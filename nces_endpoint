#!/usr/bin/env python

import os
import threading
from datetime import datetime
from argparse import ArgumentParser
from functools import wraps, update_wrapper
from flask import Flask, request, Response, abort
from flask import make_response

import ontolearn
from ontolearn.concept_learner import NCES
from ontolearn.metrics import F1
from ontolearn.utils.log_config import setup_logging

from owlapy.model import OWLNamedIndividual
from owlapy.model import IRI
from owlapy.render import DLSyntaxObjectRenderer
import logging

setup_logging()
logger = logging.getLogger(__name__)

# @ TODO: We may want to provide an endpoint without threading.
nces = None
args = None
lock = threading.Lock()
loading: bool = False
ready: bool = False
dls_renderer = DLSyntaxObjectRenderer()

def nocache(view):
    @wraps(view)
    def no_cache(*args, **kwargs):
        response = make_response(view(*args, **kwargs))
        response.headers['Last-Modified'] = datetime.now()
        response.headers['Cache-Control'] = 'no-store, no-cache, must-revalidate, post-check=0, pre-check=0, max-age=0'
        response.headers['Pragma'] = 'no-cache'
        response.headers['Expires'] = '-1'
        return response

    return update_wrapper(no_cache, view)


def sanity_checking(learning_problem, app):
    if "positive examples" not in learning_problem:
        app.logger.debug('positives key does not exist in the input. Exit!')
        exit(1)
    if "negative examples" not in learning_problem:
        app.logger.debug('negatives key does not exist in the input. Exit!')
        exit(1)

    # TODO: Sanity checking
    # TODO: Whether each input can be mapped into OWLNamedIndividual and such owl individual exist in the input KG


def create_flask_app():
    app = Flask(__name__, instance_relative_config=True, )

    @app.route('/concept_learning', methods=['POST'])
    def concept_learning_endpoint():
        """
        Accepts a json object with parameters "positives" and "negatives". Those must have as value a list of entity
        strings each.
        """
        global lock
        global ready
        global args
        lock.acquire()
        try:
            global nces
            ready = False
            learning_problem = request.get_json(force=True)
            app.logger.debug(learning_problem)

            sanity_checking(learning_problem, app)

            try:
                typed_pos = set(map(OWLNamedIndividual, map(IRI.create, set(learning_problem["positive examples"]))))
                typed_neg = set(map(OWLNamedIndividual, map(IRI.create, set(learning_problem["negative examples"]))))
                prediction = nces.fit(typed_pos, typed_neg)
            except Exception as e:
                app.logger.debug(e)
                abort(400)
            try:
                hypotheses_ser = dls_renderer.render(prediction)
            except Exception as ex:
                print(ex)
            return Response(hypotheses_ser)
        finally:
            ready = True
            lock.release()

    @app.route('/status')
    @nocache
    def status_endpoint():
        global loading
        global ready
        if loading:
            flag = "loading"
        elif ready:
            flag = "ready"
        else:
            flag = "busy"
        status = {"status": flag}
        return status

    with app.app_context():
	global lock
        with lock:
            global loading
            loading = False
            global ready
            ready = True
#    @app.before_first_request
#    def set_ready():
#        global lock
#        with lock:
#            global loading
#            loading = False
#            global ready
#            ready = True
#
#    return app


if __name__ == '__main__':
    parser = ArgumentParser()
    
    parser.add_argument("--path_knowledge_base", type=str, default='NCESData/animals/animals.owl')
    parser.add_argument("--path_knowledge_base_embeddings", type=str,
                        default='NCESData/animals/embeddings/ConEx_entity_embeddings.csv')
    args = parser.parse_args()
    nces = NCES(knowledge_base_path=args.path_knowledge_base, learner_name="SetTransformer", path_of_embeddings=args.path_knowledge_base_embeddings, max_length=48, proj_dim=128,\
         rnn_n_layers=2, drop_prob=0.1, num_heads=4, num_seeds=1, num_inds=32, load_pretrained=True, pretrained_model_name=["SetTransformer", "LSTM", "GRU"])

    loading = True
    app = create_flask_app()
    app.run(host="0.0.0.0", port=9080, processes=1)
