{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "lasting-capitol",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "* Owlready2 * Warning: optimized Cython parser module 'owlready2_optimized' is not available, defaulting to slower Python implementation\n"
     ]
    }
   ],
   "source": [
    "from ontolearn.concept_learner import NCES\n",
    "from ontolearn.knowledge_base import KnowledgeBase\n",
    "from owlapy.parser import DLSyntaxParser\n",
    "from owlapy.render import DLSyntaxObjectRenderer\n",
    "from ontolearn.metrics import F1, Accuracy, Precision, Recall\n",
    "import time\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "pleasant-cartoon",
   "metadata": {},
   "outputs": [],
   "source": [
    "def quality(solution, pos, neg):\n",
    "    f1 = F1().score2; accuracy = Accuracy().score2; precision = Precision().score2; recall = Recall().score2\n",
    "    instances = set(KB.individuals(solution))\n",
    "    if isinstance(list(pos)[0], str):\n",
    "        instances = {ind.get_iri().as_str().split(\"/\")[-1] for ind in instances}\n",
    "    tp=len(pos.intersection(instances))\n",
    "    fn=len((instances-pos).difference(neg))\n",
    "    fp=len((instances-neg).difference(pos))\n",
    "    tn=len((instances-pos).intersection(neg))\n",
    "    print(\"Accuracy: {}%\".format(100*accuracy(tp, fn, fp, tn)[-1]))\n",
    "    print(\"Precision: {}%\".format(100*precision(tp, fn, fp, tn)[-1]))\n",
    "    print(\"Recall: {}%\".format(100*recall(tp, fn, fp, tn)[-1]))\n",
    "    print(\"F1: {}%\".format(100*f1(tp, fn, fp, tn)[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "frequent-corpus",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " Loaded pretrained model! \n",
      "\n"
     ]
    }
   ],
   "source": [
    "nces = NCES(knowledge_base_path=\"./NCESData/family/family.owl\", learner_name=\"SetTransformer\",\n",
    "     path_of_embeddings=\"./NCESData/family/embeddings/ConEx_entity_embeddings.csv\", load_pretrained=True, max_length=48, proj_dim=128, rnn_n_layers=2, drop_prob=0.1, num_heads=4, num_seeds=1, num_inds=32, pretrained_model_name=\"SetTransformer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "expired-registrar",
   "metadata": {},
   "outputs": [],
   "source": [
    "KB = KnowledgeBase(path=nces.knowledge_base_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cheap-military",
   "metadata": {},
   "outputs": [],
   "source": [
    "dl_syntax_renderer = DLSyntaxObjectRenderer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "affecting-campbell",
   "metadata": {},
   "outputs": [],
   "source": [
    "atomic_classes = [dl_syntax_renderer.render(a) for a in KB.ontology().classes_in_signature()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "retained-finger",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Brother',\n",
       " 'Male',\n",
       " 'PersonWithASibling',\n",
       " 'Child',\n",
       " 'Person',\n",
       " 'Daughter',\n",
       " 'Female',\n",
       " 'Father',\n",
       " 'Parent',\n",
       " 'Grandchild',\n",
       " 'Granddaughter',\n",
       " 'Grandfather',\n",
       " 'Grandparent',\n",
       " 'Grandmother',\n",
       " 'Grandson',\n",
       " 'Mother',\n",
       " 'Sister',\n",
       " 'Son']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "atomic_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "executive-airport",
   "metadata": {},
   "outputs": [],
   "source": [
    "dl_parser = DLSyntaxParser(nces.kb_namespace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "similar-bonus",
   "metadata": {},
   "outputs": [],
   "source": [
    "brother = dl_parser.parse('Brother')\n",
    "daughter = dl_parser.parse('Daughter')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "informal-nerve",
   "metadata": {},
   "source": [
    "#### Input examples can be sets or lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "spiritual-mercy",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = set(KB.individuals(brother)).union(set(KB.individuals(daughter)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "stopped-tennessee",
   "metadata": {},
   "outputs": [],
   "source": [
    "neg = set(KB.individuals())-set(pos)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "higher-absorption",
   "metadata": {},
   "source": [
    "#### Prediction with SetTransformer (default model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "silver-banks",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction:  Son ⊔ Daughter ⊔ PersonWithASibling\n",
      "\n",
      "Duration:  0.1401386260986328  seconds\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "concept = nces.fit(pos, neg)\n",
    "t1 = time.time()\n",
    "print(\"\\nDuration: \", t1-t0, \" seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "medieval-green",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 100.0%\n",
      "Precision: 100.0%\n",
      "Recall: 100.0%\n",
      "F1: 100.0%\n"
     ]
    }
   ],
   "source": [
    "quality(concept, pos, neg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "invalid-encoding",
   "metadata": {},
   "source": [
    "### Ensemble prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "educational-reviewer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " Loaded pretrained model! \n",
      "\n",
      "\n",
      "\n",
      " Loaded pretrained model! \n",
      "\n",
      "\n",
      "\n",
      " Loaded pretrained model! \n",
      "\n",
      "Prediction:  Brother ⊔ Daughter\n",
      "\n",
      "Duration:  0.372330904006958  seconds\n"
     ]
    }
   ],
   "source": [
    "nces.pretrained_model_name = ['SetTransformer','GRU','LSTM']\n",
    "nces.refresh()\n",
    "t0 = time.time()\n",
    "concept = nces.fit(pos, neg)\n",
    "t1 = time.time()\n",
    "print(\"\\nDuration: \", t1-t0, \" seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "approximate-riding",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 100.0%\n",
      "Precision: 100.0%\n",
      "Recall: 100.0%\n",
      "F1: 100.0%\n"
     ]
    }
   ],
   "source": [
    "quality(concept, pos, neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "olympic-alert",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "deadly-defeat",
   "metadata": {},
   "source": [
    "### Complex learning problems, potentially without an exact solution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spread-journalism",
   "metadata": {},
   "source": [
    "#### First learning problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "conceptual-basics",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_individuals = set(KB.individuals())\n",
    "pos = set(random.sample(list(all_individuals), 150))\n",
    "remaining = all_individuals-pos\n",
    "neg = set(random.sample(list(remaining), min(100, len(remaining))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "golden-preserve",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['SetTransformer', 'GRU', 'LSTM']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nces.pretrained_model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "considerable-drawing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction:  Person ⊓ (∀ married.(Brother ⊔ (∀ hasChild.(¬Grandparent))))\n",
      "\n",
      "Duration:  0.3630399703979492  seconds\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "concept = nces.fit(pos, neg)\n",
    "t1 = time.time()\n",
    "print(\"\\nDuration: \", t1-t0, \" seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "caroline-destiny",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 100.0%\n",
      "Precision: 100.0%\n",
      "Recall: 100.0%\n",
      "F1: 100.0%\n"
     ]
    }
   ],
   "source": [
    "quality(concept, pos, neg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "outdoor-windsor",
   "metadata": {},
   "source": [
    "#### Second learning problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "junior-absorption",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = set(random.sample(list(all_individuals), 80))\n",
    "remaining = all_individuals-pos\n",
    "neg = set(random.sample(list(remaining), min(150, len(remaining))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "nuclear-fitting",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction:  Person ⊔ Grandchild\n",
      "\n",
      "Duration:  0.3476722240447998  seconds\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "concept = nces.fit(pos, neg)\n",
    "t1 = time.time()\n",
    "print(\"\\nDuration: \", t1-t0, \" seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "wound-sussex",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 100.0%\n",
      "Precision: 100.0%\n",
      "Recall: 100.0%\n",
      "F1: 100.0%\n"
     ]
    }
   ],
   "source": [
    "quality(concept, pos, neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "damaged-spray",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "green-implementation",
   "metadata": {},
   "source": [
    "## Important note\n",
    "\n",
    "- Each of the synthesized expressions, e.g., Person ⊓ (∀ married.(Grandfather ⊔ (∀ hasChild.Granddaughter))) are not present in the knowledge base.\n",
    "- NCES synthesizes solutions by leveraging its experience on the training data.\n",
    "- NCES can solve multiple learning problems at the same time (through broadcasting on matrix operations in its neural network component)\n",
    "- Since LSTM and GRU are not permutation-equivariant, we can get different but closely related solutions by shuflling the input examples for these architectures. For this, one needs to instantiate the NCES class with the attribute \"sorted_examples=False\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "future-willow",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nces",
   "language": "python",
   "name": "nces"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
