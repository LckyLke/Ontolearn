{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "changed-wealth",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "* Owlready2 * Warning: optimized Cython parser module 'owlready2_optimized' is not available, defaulting to slower Python implementation\n"
     ]
    }
   ],
   "source": [
    "from ontolearn.concept_learner import NCES\n",
    "from ontolearn.knowledge_base import KnowledgeBase\n",
    "from owlapy.parser import DLSyntaxParser\n",
    "from owlapy.render import DLSyntaxObjectRenderer\n",
    "from ontolearn.metrics import F1, Accuracy, Precision, Recall\n",
    "import time\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ignored-marks",
   "metadata": {},
   "outputs": [],
   "source": [
    "def quality(solution, pos, neg):\n",
    "    f1 = F1().score2; accuracy = Accuracy().score2; precision = Precision().score2; recall = Recall().score2\n",
    "    instances = set(KB.individuals(solution))\n",
    "    if isinstance(list(pos)[0], str):\n",
    "        instances = {ind.get_iri().as_str().split(\"/\")[-1] for ind in instances}\n",
    "    tp=len(pos.intersection(instances))\n",
    "    fn=len((instances-pos).difference(neg))\n",
    "    fp=len((instances-neg).difference(pos))\n",
    "    tn=len((instances-pos).intersection(neg))\n",
    "    print(\"Accuracy: {}%\".format(100*accuracy(tp, fn, fp, tn)[-1]))\n",
    "    print(\"Precision: {}%\".format(100*precision(tp, fn, fp, tn)[-1]))\n",
    "    print(\"Recall: {}%\".format(100*recall(tp, fn, fp, tn)[-1]))\n",
    "    print(\"F1: {}%\".format(100*f1(tp, fn, fp, tn)[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "conceptual-validity",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " Loaded pretrained model! \n",
      "\n"
     ]
    }
   ],
   "source": [
    "nces = NCES(knowledge_base_path=\"./NCESData/family/family.owl\", learner_name=\"SetTransformer\",\n",
    "     path_of_embeddings=\"./NCESData/family/embeddings/ConEx_entity_embeddings.csv\", load_pretrained=True, max_length=48, proj_dim=128, rnn_n_layers=2, drop_prob=0.1, num_heads=4, num_seeds=1, num_inds=32, pretrained_model_name=\"SetTransformer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "refined-pontiac",
   "metadata": {},
   "outputs": [],
   "source": [
    "KB = KnowledgeBase(path=nces.knowledge_base_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "automotive-guidance",
   "metadata": {},
   "outputs": [],
   "source": [
    "dl_syntax_renderer = DLSyntaxObjectRenderer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "reduced-uganda",
   "metadata": {},
   "outputs": [],
   "source": [
    "atomic_classes = [dl_syntax_renderer.render(a) for a in KB.ontology().classes_in_signature()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "authentic-tuition",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Brother',\n",
       " 'Male',\n",
       " 'PersonWithASibling',\n",
       " 'Child',\n",
       " 'Person',\n",
       " 'Daughter',\n",
       " 'Female',\n",
       " 'Father',\n",
       " 'Parent',\n",
       " 'Grandchild',\n",
       " 'Granddaughter',\n",
       " 'Grandfather',\n",
       " 'Grandparent',\n",
       " 'Grandmother',\n",
       " 'Grandson',\n",
       " 'Mother',\n",
       " 'Sister',\n",
       " 'Son']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "atomic_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "played-walter",
   "metadata": {},
   "outputs": [],
   "source": [
    "dl_parser = DLSyntaxParser(nces.kb_namespace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "imposed-connecticut",
   "metadata": {},
   "outputs": [],
   "source": [
    "brother = dl_parser.parse('Brother')\n",
    "daughter = dl_parser.parse('Daughter')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prescribed-radius",
   "metadata": {},
   "source": [
    "#### Input examples can be sets or lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "large-tamil",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = set(KB.individuals(brother)).union(set(KB.individuals(daughter)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "extensive-laptop",
   "metadata": {},
   "outputs": [],
   "source": [
    "neg = set(KB.individuals())-set(pos)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bright-alaska",
   "metadata": {},
   "source": [
    "#### Prediction with SetTransformer (default model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "adjusted-introduction",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction:  Son ⊔ Daughter ⊔ PersonWithASibling\n",
      "\n",
      "Duration:  0.1401386260986328  seconds\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "concept = nces.fit(pos, neg)\n",
    "t1 = time.time()\n",
    "print(\"\\nDuration: \", t1-t0, \" seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "changing-mouth",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 100.0%\n",
      "Precision: 100.0%\n",
      "Recall: 100.0%\n",
      "F1: 100.0%\n"
     ]
    }
   ],
   "source": [
    "quality(concept, pos, neg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alien-hierarchy",
   "metadata": {},
   "source": [
    "### Ensemble prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cardiac-compatibility",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " Loaded pretrained model! \n",
      "\n",
      "\n",
      "\n",
      " Loaded pretrained model! \n",
      "\n",
      "\n",
      "\n",
      " Loaded pretrained model! \n",
      "\n",
      "Prediction:  Brother ⊔ Daughter\n",
      "\n",
      "Duration:  0.372330904006958  seconds\n"
     ]
    }
   ],
   "source": [
    "nces.pretrained_model_name = ['SetTransformer','GRU','LSTM']\n",
    "nces.refresh()\n",
    "t0 = time.time()\n",
    "concept = nces.fit(pos, neg)\n",
    "t1 = time.time()\n",
    "print(\"\\nDuration: \", t1-t0, \" seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "constitutional-thanks",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 100.0%\n",
      "Precision: 100.0%\n",
      "Recall: 100.0%\n",
      "F1: 100.0%\n"
     ]
    }
   ],
   "source": [
    "quality(concept, pos, neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "southeast-creator",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "beautiful-liabilities",
   "metadata": {},
   "source": [
    "### Complex learning problems, potentially without an exact solution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "macro-aging",
   "metadata": {},
   "source": [
    "#### First learning problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "controlled-stopping",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_individuals = set(KB.individuals())\n",
    "pos = set(random.sample(list(all_individuals), 150))\n",
    "remaining = all_individuals-pos\n",
    "neg = set(random.sample(list(remaining), min(100, len(remaining))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "baking-antarctica",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['SetTransformer', 'GRU', 'LSTM']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nces.pretrained_model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "silent-wiring",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction:  Person ⊓ (∀ married.(Brother ⊔ (∀ hasChild.(¬Grandparent))))\n",
      "\n",
      "Duration:  0.3630399703979492  seconds\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "concept = nces.fit(pos, neg)\n",
    "t1 = time.time()\n",
    "print(\"\\nDuration: \", t1-t0, \" seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "verbal-waste",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 100.0%\n",
      "Precision: 100.0%\n",
      "Recall: 100.0%\n",
      "F1: 100.0%\n"
     ]
    }
   ],
   "source": [
    "quality(concept, pos, neg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "careful-wesley",
   "metadata": {},
   "source": [
    "#### Second learning problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "exotic-default",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = set(random.sample(list(all_individuals), 80))\n",
    "remaining = all_individuals-pos\n",
    "neg = set(random.sample(list(remaining), min(150, len(remaining))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "liquid-parent",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction:  Person ⊔ Grandchild\n",
      "\n",
      "Duration:  0.3476722240447998  seconds\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "concept = nces.fit(pos, neg)\n",
    "t1 = time.time()\n",
    "print(\"\\nDuration: \", t1-t0, \" seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "numerous-tooth",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 100.0%\n",
      "Precision: 100.0%\n",
      "Recall: 100.0%\n",
      "F1: 100.0%\n"
     ]
    }
   ],
   "source": [
    "quality(concept, pos, neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "foster-trading",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "overall-archive",
   "metadata": {},
   "source": [
    "## Important note\n",
    "\n",
    "- Each of the synthesized expressions, e.g., Person ⊓ (∀ married.(Brother ⊔ (∀ hasChild.(¬Grandparent)))) are not present in the knowledge base.\n",
    "- NCES synthesizes solutions by leveraging its experience on the training data.\n",
    "- The inputs (positive/negative examples) need not \n",
    "- NCES can solve multiple learning problems at the same time (through broadcasting on matrix operations in its neural network component)\n",
    "- Since LSTM and GRU are not permutation-equivariant, we can get different but closely related solutions by shuflling the input examples for these architectures. For this, one needs to instantiate the NCES class with the attribute \"sorted_examples=False\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "small-trail",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nces",
   "language": "python",
   "name": "nces"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
